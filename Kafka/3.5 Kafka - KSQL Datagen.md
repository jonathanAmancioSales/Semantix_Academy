# Kafka - KSQL Datagen

- Acessar container:
~~~shell
docker exec -it ksql-datagen bash
~~~

~~~shell
root@ksql-datagen:/# ksql-datagen help
usage: DataGen 
[help] 
[bootstrap-server=<kafka bootstrap server(s)> (defaults to localhost:9092)] 
[quickstart=<quickstart preset> (case-insensitive; one of 'orders', 'users', or 'pageviews')] 
schema=<avro schema file> 
[schemaRegistryUrl=<url for Confluent Schema Registry> (defaults to http://localhost:8081)] 
key-format=<message key format> (case-insensitive; one of 'avro', 'json', 'kafka' or 'delimited') 
value-format=<message value format> (case-insensitive; one of 'avro', 'json' or 'delimited') 
topic=<kafka topic name> 
key=<name of key column> 
[iterations=<number of rows> (if no value is specified, datagen will produce indefinitely)] 
[propertiesFile=<file specifying Kafka client properties>] 
[nThreads=<number of producer threads to start>] 
[msgRate=<rate to produce in msgs/second>] 
[printRows=<true|false>]
~~~


### 1. Criar o tópico users com os dados do ksql-datagen:
- quickstart=users
- topic=users

~~~shell
root@ksql-datagen:/# ksql-datagen bootstrap-server=broker:29092 schemaRegistryUrl=schema-registry:8081 quickstart=users topic=users

[2022-03-13 15:03:17,222] INFO AvroDataConfig values: 
    connect.meta.data = true
    enhanced.avro.schema.support = false
    schemas.cache.config = 1000
 (io.confluent.connect.avro.AvroDataConfig:347)
# [...]
User_3 --> ([ 1507845342346L | 'User_3' | 'Region_9' | 'FEMALE' ]) ts:1647183797581
User_3 --> ([ 1508607550361L | 'User_3' | 'Region_1' | 'FEMALE' ]) ts:1647183797593
User_4 --> ([ 1494477394647L | 'User_4' | 'Region_3' | 'FEMALE' ]) ts:1647183797593
# [...]
~~~

### 2. Visualizar os dados do tópico no Ksql:

~~~shell
# Acessar container:
docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
~~~

~~~ksql
ksql> print 'users' from beginning limit 6;

Key format: KAFKA_STRING
Value format: JSON or KAFKA_STRING
rowtime: 3/13/22 3:02:31 PM UTC, key: User_7, value: {"registertime":148986148852
9,"userid":"User_7","regionid":"Region_1","gender":"OTHER"}
rowtime: 3/13/22 3:02:31 PM UTC, key: User_8, value: {"registertime":151546777639
6,"userid":"User_8","regionid":"Region_9","gender":"OTHER"}
rowtime: 3/13/22 3:02:31 PM UTC, key: User_5, value: {"registertime":149339070214
6,"userid":"User_5","regionid":"Region_7","gender":"FEMALE"}
rowtime: 3/13/22 3:02:31 PM UTC, key: User_9, value: {"registertime":149593484421
0,"userid":"User_9","regionid":"Region_7","gender":"MALE"}
~~~


### 3. Criar o stream users_raw com os dados do tópico users com as seguintes propriedades:
- kafka_topic='users'
- value_format='JSON'
- key = 'userid'
- timestamp='registertime'

~~~ksql
# Apresentou erro:
ksql> create stream users_raw with (KAFKA_TOPIC='users', VALUE_FORMAT='JSON', KEY='userid', TIMESTAMP='registertime');

Schema for message values on topic users does not exist in the Schema Registry.Subject: users-value
# [...]
~~~

~~~ksql
ksql> CREATE STREAM users_raw(userid VARCHAR, registertime BIGINT) WITH (KAFKA_TOPIC='users', VALUE_FORMAT='JSON', KEY='userid', TIMESTAMP='registertime');

 Message        
----------------
 Stream created 
----------------
~~~


### 4. Visualizar a estrutura da Stream users_raw

~~~ksql
ksql> show streams;

 Stream Name         | Kafka Topic                 | Format    
---------------------------------------------------------------
 COUNT_TMP           | COUNT_TMP                   | DELIMITED 
 KSQL_PROCESSING_LOG | default_ksql_processing_log | JSON      
 USERS_RAW           | users                       | JSON      
 USUARIO_CSV         | msg-usuario-csv             | DELIMITED 
---------------------------------------------------------------
~~~


### 5. Visualizar os dados da Stream users_raw

~~~ksql
# Configurar para visualizar os dados desde o início:
ksql> SET 'auto.offset.reset'='earliest';

Successfully changed local property 'auto.offset.reset' to 'earliest'. Use the UNSET command to revert your change.
~~~

~~~ksql
ksql> select * from users_raw EMIT CHANGES limit 5;

+------------------+--------------+--------------+------------------+
|ROWTIME           |ROWKEY        |USERID        |REGISTERTIME      |
+------------------+--------------+--------------+------------------+
|1489861488529     |User_7        |User_7        |1489861488529     |
|1515467776396     |User_8        |User_8        |1515467776396     |
|1493390702146     |User_5        |User_5        |1493390702146     |
|1495934844210     |User_9        |User_9        |1495934844210     |
|1508462069409     |User_3        |User_3        |1508462069409     |
Limit Reached
Query terminated
~~~


### 6. Repetir todo o proceso para o tópico pageviews:

~~~shell
docker exec -it ksql-datagen bash

# Criar tópico:
root@ksql-datagen:/# ksql-datagen bootstrap-server=broker:29092 schemaRegistryUrl=schema-registry:8081 quickstart=pageviews topic=pageviews

# [...]
1647189708658 --> ([ 1647189708658L | 'User_1' | 'Page_51' ]) ts:1647189708911
1647189708923 --> ([ 1647189708923L | 'User_8' | 'Page_62' ]) ts:1647189708923
1647189708925 --> ([ 1647189708925L | 'User_5' | 'Page_38' ]) ts:1647189708925
1647189708925 --> ([ 1647189708925L | 'User_2' | 'Page_97' ]) ts:1647189708925
1647189708926 --> ([ 1647189708926L | 'User_7' | 'Page_24' ]) ts:1647189708926
~~~

~~~shell
docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
~~~

~~~ksql
# Visualizar dados do tópico:
ksql> print 'pageviews' from beginning limit 5;

Key format: KAFKA_BIGINT or KAFKA_DOUBLE
Value format: JSON or KAFKA_STRING
rowtime: 3/13/22 4:41:48 PM UTC, key: 1647189708658, value: {"viewtime":1647189708658,"userid":"User_1","pageid":"Page_51"}
rowtime: 3/13/22 4:41:48 PM UTC, key: 1647189708923, value: {"viewtime":1647189708923,"userid":"User_8","pageid":"Page_62"}
rowtime: 3/13/22 4:41:48 PM UTC, key: 1647189708925, value: {"viewtime":1647189708925,"userid":"User_5","pageid":"Page_38"}
rowtime: 3/13/22 4:41:48 PM UTC, key: 1647189708925, value: {"viewtime":1647189708925,"userid":"User_2","pageid":"Page_97"}
rowtime: 3/13/22 4:41:48 PM UTC, key: 1647189708926, value: {"viewtime":1647189708926,"userid":"User_7","pageid":"Page_24"}
~~~

~~~ksql
# Criar stream:
ksql> CREATE STREAM pageviews_raw(userid VARCHAR, pageid VARCHAR, viewtime BIGINT) WITH (KAFKA_TOPIC='pageviews', VALUE_FORMAT='JSON', KEY='userid', TIMESTAMP='viewtime');

 Message        
----------------
 Stream created 
----------------
~~~

~~~ksql
# Visualizar dados do Stream:
ksql> select USERID,PAGEID,VIEWTIME from pageviews_raw EMIT CHANGES limit 5;

+-------------------------+-------------------------+-------------------------+
|USERID                   |PAGEID                   |VIEWTIME                 |
+-------------------------+-------------------------+-------------------------+
|User_1                   |Page_51                  |1647189708658            |
|User_8                   |Page_62                  |1647189708923            |
|User_5                   |Page_38                  |1647189708925            |
|User_2                   |Page_97                  |1647189708925            |
|User_7                   |Page_24                  |1647189708926            |
Limit Reached
Query terminated
~~~

###################